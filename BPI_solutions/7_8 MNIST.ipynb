{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot options\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "# plt.rcParams['figure.figsize'] = [16, 10] # for big plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "#print option\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "# pd.set_option('display.max_rows',100)\n",
    "# clear output in Jupyter cell\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data and split into train, valid, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000 train instances\n",
      "10500 valid instances\n",
      "10500 test instances\n"
     ]
    }
   ],
   "source": [
    "print('{} train instances'.format(X_train.shape[0]))\n",
    "print('{} valid instances'.format(X_valid.shape[0]))\n",
    "print('{} test instances'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a few models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, probability=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='rbf',C=10,probability=True)\n",
    "# fit\n",
    "svm_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preds\n",
    "svm_preds=svm_clf.predict(X_valid)\n",
    "# get probs\n",
    "svm_probs=svm_clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy = 0.981\n"
     ]
    }
   ],
   "source": [
    "print('SVM accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid,svm_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "# fit\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preds\n",
    "knn_preds=knn_clf.predict(X_valid)\n",
    "# get probs\n",
    "knn_probs=knn_clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy = 0.972\n"
     ]
    }
   ],
   "source": [
    "print('KNN accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid,knn_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb_clf=HistGradientBoostingClassifier()\n",
    "# fit\n",
    "hgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preds\n",
    "hgb_preds=hgb_clf.predict(X_valid)\n",
    "# get probs\n",
    "hgb_probs=hgb_clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGB accuracy = 0.972\n"
     ]
    }
   ],
   "source": [
    "print('HGB accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid,hgb_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "catpreds=pd.DataFrame(data={'knn':knn_preds,'svm':svm_preds,'hgb':hgb_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting accuracy = 0.981\n"
     ]
    }
   ],
   "source": [
    "print('hard voting accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid,catpreds.mode(axis=1)[0].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be of limited utility bc the KNN prbablity isn't very helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack the probability arrays along a third dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=np.stack((knn_probs,svm_probs,hgb_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10500, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mean) soft voting accuracy = 0.981\n"
     ]
    }
   ],
   "source": [
    "mean_probs=probs.mean(axis=0).argmax(axis=1)\n",
    "print('(mean) soft voting accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid.astype(int),mean_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(median) soft voting accuracy = 0.981\n"
     ]
    }
   ],
   "source": [
    "med_probs=np.median(probs,axis=0).argmax(axis=1)\n",
    "print('(median) soft voting accuracy = {:.3f}'.format(metrics.accuracy_score(y_valid.astype(int),med_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preds\n",
    "svm_preds=svm_clf.predict(X_test)\n",
    "knn_preds=knn_clf.predict(X_test)\n",
    "hgb_preds=hgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy = 0.984\n",
      "KNN accuracy = 0.973\n",
      "HGB accuracy = 0.977\n"
     ]
    }
   ],
   "source": [
    "print('SVM accuracy = {:.3f}'.format(metrics.accuracy_score(y_test,svm_preds)))\n",
    "print('KNN accuracy = {:.3f}'.format(metrics.accuracy_score(y_test,knn_preds)))\n",
    "print('HGB accuracy = {:.3f}'.format(metrics.accuracy_score(y_test,hgb_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting accuracy = 0.984\n"
     ]
    }
   ],
   "source": [
    "catpreds=pd.DataFrame(data={'knn':knn_preds,'svm':svm_preds,'hgb':hgb_preds})\n",
    "print('hard voting accuracy = {:.3f}'.format(metrics.accuracy_score(y_test,catpreds.mode(axis=1)[0].values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
